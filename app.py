import streamlit as st
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import numpy as np
from PIL import Image
import tensorflow_hub as hub
from streamlit_drawable_canvas import st_canvas


import sys

st.write("ğŸ§ª ç¾åœ¨ä½¿ã‚ã‚Œã¦ã„ã‚‹ Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³:", sys.version)


# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆç”»åƒç”¨ï¼‰
model = tf.keras.applications.MobileNetV2(weights='imagenet')

# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆæ‰‹æ›¸ãç”¨ï¼‰
quickdraw_model = hub.load('https://tfhub.dev/google/quickdraw/monotask/imagenet/classification/1')

# ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—
@st.cache_resource
def load_quickdraw_labels():
    labels_url = "https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt"
    return list(np.loadtxt(labels_url, dtype=str, delimiter="\n"))

quickdraw_labels = load_quickdraw_labels()


def preprocess_image(img):
    img = img.resize((224, 224))  # ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
    img_array = np.array(img)  # NumPy é…åˆ—ã«å¤‰æ›
    img_array = np.expand_dims(img_array, axis=0)  # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)  # ãƒ¢ãƒ‡ãƒ«ã«é©ã—ãŸå‰å‡¦ç†
    return img_array

def predict_image(img):
    preprocessed_img = preprocess_image(img)
    preds = model.predict(preprocessed_img)  # äºˆæ¸¬ã‚’å®Ÿè¡Œ
    decoded_preds = tf.keras.applications.mobilenet_v2.decode_predictions(preds)[0]
    return decoded_preds


def predict_quickdraw(img):
    img = img.resize((224, 224))  # QuickDrawã¯224x224ãŒå…¥åŠ›ã‚µã‚¤ã‚º
    img_array = np.array(img)  # NumPy é…åˆ—ã«å¤‰æ›
    img_array = np.expand_dims(img_array, axis=0)  # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
    img_array = tf.cast(img_array, tf.float32)  # æµ®å‹•å°æ•°ç‚¹å‹ã«å¤‰æ›

    preds = quickdraw_model(img_array)  # äºˆæ¸¬
    return preds.numpy()


st.title("ImageRecognition")

uploaded_image = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png"])

if uploaded_image is not None:
    img = Image.open(uploaded_image)
    st.image(img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒ", use_container_width=True)
    # ç”»åƒèªè­˜ã‚’è¡Œã†
    predictions = predict_image(img)
    # çµæœã‚’è¡¨ç¤º
    st.write("æ¤œå‡ºã•ã‚ŒãŸç‰©ä½“:")
    for pred in predictions:
        st.write(f"{pred[1]} (ç¢ºç‡: {pred[2]*100:.2f}%)")


st.subheader("ã‚­ãƒ£ãƒ³ãƒã‚¹ã«çµµã‚’æã„ã¦ãã ã•ã„")
canvas_result = st_canvas(
    fill_color="rgba(255, 255, 255, 1)",
    stroke_width=10,
    stroke_color="#000000",
    background_color="#ffffff",
    width=224,
    height=224,
    drawing_mode="freedraw",
    key="canvas",
)

# æ‰‹æãã®ã‚­ãƒ£ãƒ³ãƒã‚¹ã‹ã‚‰ç”»åƒã‚’å–å¾—ã—ãŸå ´åˆ
if canvas_result.image_data is not None:
    img_array = canvas_result.image_data.astype("uint8")
    img_pil = Image.fromarray(img_array)

    st.image(img_pil, caption="æã„ãŸç”»åƒ", use_container_width=False)

    preds = predict_quickdraw(img_pil)
    predicted_index = np.argmax(preds)
    predicted_label = quickdraw_labels[predicted_index]

    st.write("æ‰‹æãã§èªè­˜ã•ã‚ŒãŸç‰©ä½“:")
    st.write(f"äºˆæ¸¬: {predicted_label}ï¼ˆä¿¡é ¼åº¦: {np.max(preds)*100:.2f}ï¼…ï¼‰")

